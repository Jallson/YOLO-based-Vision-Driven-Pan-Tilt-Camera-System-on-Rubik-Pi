# YOLO-based-Vision-Driven-Pan-Tilt-Camera-System-on-Rubik-Pi
This project is relatively simple: it translates the location of an object or a person’s face into movements of two servos (pan–tilt) that control a camera. In essence, this creates a camera that can automatically follow its target. The system uses an object detection model trained in Edge Impulse Studio, specifically YOLO-Pro to leverage transfer learning and pre-trained weights. This approach significantly reduces the amount of training data required while improving object recognition accuracy. This model deployed as an embedded .eim model running on our Python program. The system also utilizes Rubik Pi 3, which has GPIO compatibility similar to the Raspberry Pi. This allows the use of the PCA9685 via I²C communication to control LED lights or servo motors. Rubik Pi 3 has proven to be highly reliable, delivering real-time inference performance in our previous projects.

In this implementation, we first control a row of 16 LEDs that illuminate from left to right following the horizontal movement of the detected object (hand gestures), while the brightness level corresponds to the object’s vertical movement. Once this is successfully achieved, then extended to the system controls a pan–tilt camera platform driven by two servo motors, allowing the camera to dynamically follow detected objects in real time. Horizontal object movement controls the pan axis, while vertical movement controls the tilt axis, resulting intuitive tracking behavior. 
